/**
 * PostProcessor.ts - Post-Recording Pipeline Orchestrator
 *
 * Runs the full post-processing pipeline after a recording session stops:
 *   1. Transcribe audio via WhisperService batch mode
 *   2. Analyze transcript to find key moments (heuristic-based)
 *   3. Extract video frames at those timestamps via ffmpeg
 *   4. Return combined result for markdown report generation
 *
 * Designed to degrade gracefully: if frame extraction fails (e.g. ffmpeg
 * not installed), the pipeline still returns a transcript-only result.
 *
 * Part of the post-processing pipeline that runs after recording stops.
 */

import { whisperService } from '../transcription/WhisperService';
import { TranscriptAnalyzer, transcriptAnalyzer } from './TranscriptAnalyzer';
import { FrameExtractor, frameExtractor } from './FrameExtractor';

// ============================================================================
// Types
// ============================================================================

export interface TranscriptSegment {
  text: string;
  startTime: number; // seconds from start of recording
  endTime: number;
  confidence: number;
}

export interface ExtractedFrame {
  path: string; // path to extracted PNG
  timestamp: number; // seconds from start of recording
  reason: string; // why this frame was selected
  transcriptSegment?: TranscriptSegment; // associated transcript segment
}

export interface PostProcessResult {
  transcriptSegments: TranscriptSegment[];
  extractedFrames: ExtractedFrame[];
  reportPath: string;
}

export interface PostProcessProgress {
  step: 'transcribing' | 'analyzing' | 'extracting-frames' | 'generating-report';
  percent: number;
  message: string;
}

export interface PostProcessOptions {
  videoPath: string;
  audioPath: string;
  sessionDir: string;
  onProgress?: (progress: PostProcessProgress) => void;
}

// ============================================================================
// PostProcessor Class
// ============================================================================

export class PostProcessor {
  private analyzer: TranscriptAnalyzer;
  private extractor: FrameExtractor;

  constructor(
    analyzer: TranscriptAnalyzer = transcriptAnalyzer,
    extractor: FrameExtractor = frameExtractor
  ) {
    this.analyzer = analyzer;
    this.extractor = extractor;
  }

  /**
   * Run the full post-processing pipeline.
   *
   * @param options - Pipeline configuration (paths, progress callback)
   * @returns Combined result with transcript, frames, and report path
   */
  async process(options: PostProcessOptions): Promise<PostProcessResult> {
    const { videoPath, audioPath, sessionDir, onProgress } = options;

    const emitProgress = (progress: PostProcessProgress): void => {
      if (onProgress) {
        onProgress(progress);
      }
    };

    // -----------------------------------------------------------------------
    // Step 1: Transcribe audio (0-40%)
    // -----------------------------------------------------------------------
    emitProgress({
      step: 'transcribing',
      percent: 0,
      message: 'Transcribing audio...',
    });

    let segments: TranscriptSegment[];

    try {
      emitProgress({
        step: 'transcribing',
        percent: 5,
        message: 'Loading Whisper model...',
      });

      // Call WhisperService.transcribeFile() - implemented by Agent B
      // Returns an array compatible with TranscriptSegment
      const whisperResults = await whisperService.transcribeFile(audioPath);

      segments = whisperResults.map((result) => ({
        text: result.text,
        startTime: result.startTime,
        endTime: result.endTime,
        confidence: result.confidence,
      }));

      emitProgress({
        step: 'transcribing',
        percent: 40,
        message: `Transcription complete: ${segments.length} segments`,
      });

      this.log(`Transcription complete: ${segments.length} segments`);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      this.log(`Transcription failed: ${message}`);

      // Return empty result if transcription fails entirely
      return {
        transcriptSegments: [],
        extractedFrames: [],
        reportPath: sessionDir,
      };
    }

    if (segments.length === 0) {
      this.log('No transcript segments found, returning empty result');
      emitProgress({
        step: 'generating-report',
        percent: 100,
        message: 'No speech detected in recording',
      });

      return {
        transcriptSegments: [],
        extractedFrames: [],
        reportPath: sessionDir,
      };
    }

    // -----------------------------------------------------------------------
    // Step 2: Analyze transcript for key moments (40-50%)
    // -----------------------------------------------------------------------
    emitProgress({
      step: 'analyzing',
      percent: 40,
      message: 'Analyzing transcript for key moments...',
    });

    const keyMoments = this.analyzer.analyze(segments);

    emitProgress({
      step: 'analyzing',
      percent: 50,
      message: `Found ${keyMoments.length} key moments`,
    });

    this.log(`Analysis complete: ${keyMoments.length} key moments identified`);

    // -----------------------------------------------------------------------
    // Step 3: Extract frames from video (50-90%)
    // -----------------------------------------------------------------------
    emitProgress({
      step: 'extracting-frames',
      percent: 50,
      message: 'Extracting video frames...',
    });

    let extractedFrames: ExtractedFrame[] = [];

    try {
      const timestamps = keyMoments.map((m) => m.timestamp);

      const extractionResult = await this.extractor.extract({
        videoPath,
        timestamps,
        outputDir: sessionDir,
      });

      if (!extractionResult.ffmpegAvailable) {
        this.log('ffmpeg not available, skipping frame extraction');
        emitProgress({
          step: 'extracting-frames',
          percent: 90,
          message: 'Frame extraction skipped (ffmpeg not installed)',
        });
      } else {
        // Map extraction results to ExtractedFrame with associated transcript segments
        extractedFrames = extractionResult.frames
          .filter((f) => f.success)
          .map((frame) => {
            // Find the key moment that corresponds to this frame
            const moment = keyMoments.find(
              (m) => Math.abs(m.timestamp - frame.timestamp) < 0.5
            );

            // Find the closest transcript segment
            const closestSegment = this.findClosestSegment(
              frame.timestamp,
              segments
            );

            return {
              path: frame.path,
              timestamp: frame.timestamp,
              reason: moment?.reason ?? 'Extracted frame',
              transcriptSegment: closestSegment,
            };
          });

        emitProgress({
          step: 'extracting-frames',
          percent: 90,
          message: `Extracted ${extractedFrames.length} frames`,
        });

        this.log(`Frame extraction complete: ${extractedFrames.length} frames`);
      }
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      this.log(`Frame extraction failed: ${message} - continuing with transcript only`);

      emitProgress({
        step: 'extracting-frames',
        percent: 90,
        message: 'Frame extraction failed, continuing with transcript only',
      });

      // Continue with transcript-only result - do not throw
    }

    // -----------------------------------------------------------------------
    // Step 4: Return result (90-100%)
    // -----------------------------------------------------------------------
    emitProgress({
      step: 'generating-report',
      percent: 90,
      message: 'Preparing results...',
    });

    const result: PostProcessResult = {
      transcriptSegments: segments,
      extractedFrames,
      reportPath: sessionDir,
    };

    emitProgress({
      step: 'generating-report',
      percent: 100,
      message: 'Post-processing complete',
    });

    this.log(
      `Pipeline complete: ${segments.length} segments, ${extractedFrames.length} frames`
    );

    return result;
  }

  // ============================================================================
  // Private Methods
  // ============================================================================

  /**
   * Find the transcript segment closest to a given timestamp.
   * Prefers segments that contain the timestamp; falls back to nearest start time.
   */
  private findClosestSegment(
    timestamp: number,
    segments: TranscriptSegment[]
  ): TranscriptSegment | undefined {
    if (segments.length === 0) {
      return undefined;
    }

    // First, check if timestamp falls within any segment
    for (const segment of segments) {
      if (timestamp >= segment.startTime && timestamp <= segment.endTime) {
        return segment;
      }
    }

    // Otherwise, find the closest segment by start time
    let closest = segments[0];
    let minDistance = Math.abs(timestamp - closest.startTime);

    for (let i = 1; i < segments.length; i++) {
      const distance = Math.abs(timestamp - segments[i].startTime);
      if (distance < minDistance) {
        minDistance = distance;
        closest = segments[i];
      }
    }

    return closest;
  }

  /**
   * Log helper with consistent prefix.
   */
  private log(message: string): void {
    const timestamp = new Date().toISOString();
    console.log(`[PostProcessor ${timestamp}] ${message}`);
  }
}

// ============================================================================
// Singleton Export
// ============================================================================

export const postProcessor = new PostProcessor();
export default PostProcessor;
